#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è‡ªåŠ¨çŸ¥è¯†åº“ç®¡ç†å™¨
ç›‘æ§æŒ‡å®šæ–‡ä»¶å¤¹ï¼Œè‡ªåŠ¨æ·»åŠ æ–°æ–‡æ¡£åˆ°LangChainçŸ¥è¯†åº“

åŠŸèƒ½:
- å¯åŠ¨æ—¶è‡ªåŠ¨æ‰«ææ–‡ä»¶å¤¹
- æ£€æµ‹æ–°å¢ã€ä¿®æ”¹ã€åˆ é™¤çš„æ–‡ä»¶
- è‡ªåŠ¨åˆ†ç±»å’Œæ·»åŠ åˆ°çŸ¥è¯†åº“
- æ”¯æŒå¤šç§æ–‡ä»¶æ ¼å¼
- æ™ºèƒ½å»é‡å’Œæ›´æ–°

ä½œè€…: Dragon Robot AI System
åˆ›å»ºæ—¶é—´: 2024
"""

import os
import json
import logging
import hashlib
from pathlib import Path
from typing import Dict, List, Set, Optional, Tuple
from datetime import datetime
import time

# å¯¼å…¥çŸ¥è¯†åº“ç®¡ç†å™¨
try:
    from langchain_kb_manager import UnifiedKnowledgeBaseManager
    KB_AVAILABLE = True
except ImportError:
    KB_AVAILABLE = False
    print("âš ï¸ çŸ¥è¯†åº“ç®¡ç†å™¨æœªæ‰¾åˆ°")

logger = logging.getLogger(__name__)

class AutoKnowledgeBaseManager:
    """è‡ªåŠ¨çŸ¥è¯†åº“ç®¡ç†å™¨"""
    
    def __init__(self, 
                 watch_dirs: List[str] = None,
                 kb_dir: str = "knowledge_base",
                 metadata_file: str = "auto_kb_metadata.json"):
        """
        åˆå§‹åŒ–è‡ªåŠ¨ç®¡ç†å™¨
        
        Args:
            watch_dirs: ç›‘æ§çš„æ–‡ä»¶å¤¹åˆ—è¡¨
            kb_dir: çŸ¥è¯†åº“ç›®å½•
            metadata_file: å…ƒæ•°æ®æ–‡ä»¶
        """
        # é»˜è®¤ç›‘æ§ç›®å½•
        if watch_dirs is None:
            watch_dirs = ["knowledge_base/files"]
        
        self.watch_dirs = [Path(d) for d in watch_dirs]
        self.kb_dir = kb_dir
        self.metadata_file = Path(metadata_file)
        
        # æ”¯æŒçš„æ–‡ä»¶æ ¼å¼
        self.supported_formats = {'.pdf', '.docx', '.doc', '.txt', '.md', '.markdown'}
        
        # æ–‡ä»¶å…ƒæ•°æ®
        self.file_metadata = self._load_metadata()
        
        # åˆå§‹åŒ–çŸ¥è¯†åº“ç®¡ç†å™¨
        if KB_AVAILABLE:
            self.kb_manager = UnifiedKnowledgeBaseManager(kb_dir=kb_dir)
            logger.info("âœ… çŸ¥è¯†åº“ç®¡ç†å™¨åˆå§‹åŒ–æˆåŠŸ")
        else:
            self.kb_manager = None
            logger.error("âŒ çŸ¥è¯†åº“ç®¡ç†å™¨åˆå§‹åŒ–å¤±è´¥")
        
        # åˆ†ç±»è§„åˆ™
        self.category_rules = {
            'manual': ['æ‰‹å†Œ', 'è¯´æ˜ä¹¦', 'manual', 'guide', 'æŒ‡å—'],
            'policy': ['åˆ¶åº¦', 'è§„ç« ', 'æ”¿ç­–', 'policy', 'ç®¡ç†'],
            'tech': ['æŠ€æœ¯', 'å¼€å‘', 'api', 'tech', 'é…ç½®', 'config'],
            'faq': ['é—®ç­”', 'faq', 'å¸¸è§é—®é¢˜', 'help', 'å¸®åŠ©'],
            'robot': ['æœºå™¨äºº', 'robot', 'æ§åˆ¶', 'control'],
            'official': ['å®˜æ–¹', 'official', 'readme', 'example']
        }
        
        logger.info(f"è‡ªåŠ¨çŸ¥è¯†åº“ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆï¼Œç›‘æ§ç›®å½•: {[str(d) for d in self.watch_dirs]}")
    
    def _load_metadata(self) -> Dict[str, Dict]:
        """åŠ è½½æ–‡ä»¶å…ƒæ•°æ®"""
        if self.metadata_file.exists():
            try:
                with open(self.metadata_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except Exception as e:
                logger.warning(f"å…ƒæ•°æ®åŠ è½½å¤±è´¥: {e}")
        
        return {
            "last_scan": None,
            "files": {},
            "scan_count": 0
        }
    
    def _save_metadata(self):
        """ä¿å­˜æ–‡ä»¶å…ƒæ•°æ®"""
        try:
            with open(self.metadata_file, 'w', encoding='utf-8') as f:
                json.dump(self.file_metadata, f, ensure_ascii=False, indent=2)
        except Exception as e:
            logger.error(f"å…ƒæ•°æ®ä¿å­˜å¤±è´¥: {e}")
    
    def _get_file_hash(self, file_path: Path) -> str:
        """è®¡ç®—æ–‡ä»¶MD5å“ˆå¸Œå€¼"""
        try:
            hash_md5 = hashlib.md5()
            with open(file_path, "rb") as f:
                for chunk in iter(lambda: f.read(4096), b""):
                    hash_md5.update(chunk)
            return hash_md5.hexdigest()
        except Exception as e:
            logger.warning(f"è®¡ç®—æ–‡ä»¶å“ˆå¸Œå¤±è´¥ {file_path}: {e}")
            return ""
    
    def _detect_category(self, file_path: Path) -> str:
        """æ™ºèƒ½æ£€æµ‹æ–‡ä»¶åˆ†ç±»"""
        file_name = file_path.name.lower()
        file_content = ""
        
        # å°è¯•è¯»å–æ–‡ä»¶å†…å®¹ç‰‡æ®µè¿›è¡Œåˆ†ç±»
        try:
            if file_path.suffix.lower() == '.txt':
                with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                    file_content = f.read(500).lower()  # åªè¯»å‰500å­—ç¬¦
        except:
            pass
        
        # æ ¹æ®æ–‡ä»¶åå’Œå†…å®¹æ£€æµ‹åˆ†ç±»
        search_text = f"{file_name} {file_content}"
        
        for category, keywords in self.category_rules.items():
            if any(keyword in search_text for keyword in keywords):
                return category
        
        # æ ¹æ®æ–‡ä»¶å¤¹åç§°æ¨æ–­
        parent_name = file_path.parent.name.lower()
        for category, keywords in self.category_rules.items():
            if any(keyword in parent_name for keyword in keywords):
                return category
        
        return "general"
    
    def scan_directories(self) -> Tuple[List[Path], List[Path], List[str]]:
        """
        æ‰«æç›‘æ§ç›®å½•ï¼Œæ£€æµ‹æ–‡ä»¶å˜åŒ–
        
        Returns:
            Tuple[æ–°æ–‡ä»¶åˆ—è¡¨, ä¿®æ”¹æ–‡ä»¶åˆ—è¡¨, åˆ é™¤æ–‡ä»¶åˆ—è¡¨]
        """
        current_files = {}
        new_files = []
        modified_files = []
        
        # æ‰«ææ‰€æœ‰ç›‘æ§ç›®å½•
        for watch_dir in self.watch_dirs:
            if not watch_dir.exists():
                logger.warning(f"ç›‘æ§ç›®å½•ä¸å­˜åœ¨: {watch_dir}")
                continue
            
            logger.info(f"æ‰«æç›®å½•: {watch_dir}")
            
            for file_path in watch_dir.rglob("*"):
                if (file_path.is_file() and 
                    file_path.suffix.lower() in self.supported_formats):
                    
                    file_key = str(file_path)
                    current_files[file_key] = file_path
                    
                    # è®¡ç®—æ–‡ä»¶ä¿¡æ¯
                    file_stat = file_path.stat()
                    file_size = file_stat.st_size
                    file_hash = self._get_file_hash(file_path)
                    
                    # æ£€æŸ¥æ˜¯å¦ä¸ºæ–°æ–‡ä»¶æˆ–ä¿®æ”¹çš„æ–‡ä»¶
                    if file_key not in self.file_metadata["files"]:
                        # æ–°æ–‡ä»¶
                        new_files.append(file_path)
                        logger.info(f"å‘ç°æ–°æ–‡ä»¶: {file_path.name}")
                    else:
                        # æ£€æŸ¥æ˜¯å¦ä¿®æ”¹
                        old_info = self.file_metadata["files"][file_key]
                        if (old_info.get("hash") != file_hash or 
                            old_info.get("size") != file_size):
                            modified_files.append(file_path)
                            logger.info(f"æ–‡ä»¶å·²ä¿®æ”¹: {file_path.name}")
                    
                    # æ›´æ–°å…ƒæ•°æ®
                    self.file_metadata["files"][file_key] = {
                        "size": file_size,
                        "hash": file_hash,
                        "last_modified": file_stat.st_mtime,
                        "last_checked": time.time(),
                        "category": self._detect_category(file_path)
                    }
        
        # æ£€æµ‹åˆ é™¤çš„æ–‡ä»¶
        deleted_files = []
        for file_key in list(self.file_metadata["files"].keys()):
            if file_key not in current_files:
                deleted_files.append(file_key)
                del self.file_metadata["files"][file_key]
                logger.info(f"æ–‡ä»¶å·²åˆ é™¤: {Path(file_key).name}")
        
        # æ›´æ–°æ‰«æç»Ÿè®¡
        self.file_metadata["last_scan"] = datetime.now().isoformat()
        self.file_metadata["scan_count"] = self.file_metadata.get("scan_count", 0) + 1
        
        return new_files, modified_files, deleted_files
    
    def add_file_to_kb(self, file_path: Path) -> bool:
        """æ·»åŠ æ–‡ä»¶åˆ°çŸ¥è¯†åº“"""
        if not self.kb_manager:
            logger.error("çŸ¥è¯†åº“ç®¡ç†å™¨æœªåˆå§‹åŒ–")
            return False
        
        try:
            category = self._detect_category(file_path)
            success = self.kb_manager.add_document(str(file_path), category)
            
            if success:
                logger.info(f"âœ… æˆåŠŸæ·»åŠ åˆ°çŸ¥è¯†åº“: {file_path.name} (åˆ†ç±»: {category})")
                
                # æ›´æ–°å…ƒæ•°æ®
                file_key = str(file_path)
                if file_key in self.file_metadata["files"]:
                    self.file_metadata["files"][file_key]["in_kb"] = True
                    self.file_metadata["files"][file_key]["added_time"] = time.time()
                    self.file_metadata["files"][file_key]["status"] = "success"
                
                return True
            else:
                logger.warning(f"âš ï¸ è·³è¿‡æ–‡æ¡£ï¼ˆå¯èƒ½æ˜¯æ‰«æç‰ˆæˆ–ç©ºå†…å®¹ï¼‰: {file_path.name}")
                
                # è®°å½•è·³è¿‡çŠ¶æ€
                file_key = str(file_path)
                if file_key in self.file_metadata["files"]:
                    self.file_metadata["files"][file_key]["in_kb"] = False
                    self.file_metadata["files"][file_key]["status"] = "skipped_empty_content"
                    self.file_metadata["files"][file_key]["skip_reason"] = "Empty content or scanned PDF"
                
                return False
                
        except Exception as e:
            logger.error(f"æ·»åŠ æ–‡ä»¶åˆ°çŸ¥è¯†åº“æ—¶å‡ºé”™ {file_path.name}: {e}")
            return False
    
    def auto_update_knowledge_base(self) -> Dict[str, int]:
        """è‡ªåŠ¨æ›´æ–°çŸ¥è¯†åº“"""
        logger.info("ğŸ”„ å¼€å§‹è‡ªåŠ¨æ›´æ–°çŸ¥è¯†åº“...")
        
        # æ‰«ææ–‡ä»¶å˜åŒ–
        new_files, modified_files, deleted_files = self.scan_directories()
        
        stats = {
            "new_added": 0,
            "modified_updated": 0,
            "deleted_removed": 0,
            "errors": 0
        }
        
        # å¤„ç†æ–°æ–‡ä»¶
        for file_path in new_files:
            if self.add_file_to_kb(file_path):
                stats["new_added"] += 1
            else:
                stats["errors"] += 1
        
        # å¤„ç†ä¿®æ”¹çš„æ–‡ä»¶ï¼ˆé‡æ–°æ·»åŠ ï¼‰
        for file_path in modified_files:
            if self.add_file_to_kb(file_path):
                stats["modified_updated"] += 1
            else:
                stats["errors"] += 1
        
        # å¤„ç†åˆ é™¤çš„æ–‡ä»¶ï¼ˆçŸ¥è¯†åº“ä¸­çš„æ¸…ç†éœ€è¦é‡å»ºç´¢å¼•ï¼‰
        if deleted_files:
            stats["deleted_removed"] = len(deleted_files)
            logger.info(f"ğŸ“ æ£€æµ‹åˆ° {len(deleted_files)} ä¸ªæ–‡ä»¶è¢«åˆ é™¤ï¼Œå»ºè®®é‡å»ºçŸ¥è¯†åº“ç´¢å¼•")
        
        # ä¿å­˜å…ƒæ•°æ®
        self._save_metadata()
        
        # ç”Ÿæˆæ›´æ–°æŠ¥å‘Š
        total_processed = stats["new_added"] + stats["modified_updated"]
        logger.info(f"ğŸ‰ çŸ¥è¯†åº“æ›´æ–°å®Œæˆ: æ–°å¢{stats['new_added']}ä¸ªï¼Œæ›´æ–°{stats['modified_updated']}ä¸ªï¼Œåˆ é™¤{stats['deleted_removed']}ä¸ª")
        
        if stats["errors"] > 0:
            logger.warning(f"âš ï¸ å¤„ç†è¿‡ç¨‹ä¸­å‡ºç° {stats['errors']} ä¸ªé”™è¯¯")
        
        return stats
    
    def get_status(self) -> Dict:
        """è·å–è‡ªåŠ¨ç®¡ç†å™¨çŠ¶æ€"""
        if not self.kb_manager:
            kb_stats = {"error": "çŸ¥è¯†åº“ç®¡ç†å™¨æœªåˆå§‹åŒ–"}
        else:
            kb_stats = self.kb_manager.get_stats()
        
        return {
            "watch_directories": [str(d) for d in self.watch_dirs],
            "supported_formats": list(self.supported_formats),
            "total_files": len(self.file_metadata["files"]),
            "last_scan": self.file_metadata.get("last_scan"),
            "scan_count": self.file_metadata.get("scan_count", 0),
            "knowledge_base": kb_stats,
            "categories": list(self.category_rules.keys())
        }
    
    def force_rescan(self) -> Dict[str, int]:
        """å¼ºåˆ¶é‡æ–°æ‰«æå¹¶æ›´æ–°æ‰€æœ‰æ–‡ä»¶"""
        logger.info("ğŸ”„ å¼ºåˆ¶é‡æ–°æ‰«ææ‰€æœ‰æ–‡ä»¶...")
        
        # æ¸…ç©ºå·²æœ‰è®°å½•ï¼Œå¼ºåˆ¶é‡æ–°å¤„ç†æ‰€æœ‰æ–‡ä»¶
        self.file_metadata["files"] = {}
        
        return self.auto_update_knowledge_base()


def main():
    """å‘½ä»¤è¡Œä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description="è‡ªåŠ¨çŸ¥è¯†åº“ç®¡ç†å™¨")
    parser.add_argument("--watch-dir", action="append", 
                       help="æ·»åŠ ç›‘æ§ç›®å½• (å¯æŒ‡å®šå¤šä¸ª)")
    parser.add_argument("--scan", action="store_true", 
                       help="æ‰§è¡Œä¸€æ¬¡æ‰«ææ›´æ–°")
    parser.add_argument("--force-rescan", action="store_true", 
                       help="å¼ºåˆ¶é‡æ–°æ‰«ææ‰€æœ‰æ–‡ä»¶")
    parser.add_argument("--status", action="store_true", 
                       help="æ˜¾ç¤ºçŠ¶æ€ä¿¡æ¯")
    parser.add_argument("--log-level", choices=["DEBUG", "INFO", "WARNING", "ERROR"], 
                       default="INFO", help="æ—¥å¿—çº§åˆ«")
    
    args = parser.parse_args()
    
    # è®¾ç½®æ—¥å¿—
    logging.basicConfig(
        level=getattr(logging, args.log_level),
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    # ç¡®å®šç›‘æ§ç›®å½•
    watch_dirs = args.watch_dir if args.watch_dir else ["knowledge_base/files"]
    
    # åˆ›å»ºè‡ªåŠ¨ç®¡ç†å™¨
    auto_manager = AutoKnowledgeBaseManager(watch_dirs=watch_dirs)
    
    if args.status:
        # æ˜¾ç¤ºçŠ¶æ€
        status = auto_manager.get_status()
        print("=== è‡ªåŠ¨çŸ¥è¯†åº“ç®¡ç†å™¨çŠ¶æ€ ===")
        for key, value in status.items():
            if isinstance(value, dict):
                print(f"{key}:")
                for sub_key, sub_value in value.items():
                    print(f"  {sub_key}: {sub_value}")
            else:
                print(f"{key}: {value}")
    
    elif args.force_rescan:
        # å¼ºåˆ¶é‡æ–°æ‰«æ
        stats = auto_manager.force_rescan()
        print(f"å¼ºåˆ¶é‡æ–°æ‰«æå®Œæˆ: {stats}")
    
    elif args.scan:
        # æ‰§è¡Œæ‰«ææ›´æ–°
        stats = auto_manager.auto_update_knowledge_base()
        print(f"æ‰«ææ›´æ–°å®Œæˆ: {stats}")
    
    else:
        print("ä½¿ç”¨ --help æŸ¥çœ‹å¯ç”¨é€‰é¡¹")
        print("\nå¿«é€Ÿå¼€å§‹:")
        print("  python3 auto_kb_manager.py --scan        # æ‰«æå¹¶æ›´æ–°çŸ¥è¯†åº“")
        print("  python3 auto_kb_manager.py --status      # æŸ¥çœ‹çŠ¶æ€")
        print("  python3 auto_kb_manager.py --force-rescan # å¼ºåˆ¶é‡æ–°æ‰«æ")


if __name__ == "__main__":
    main()