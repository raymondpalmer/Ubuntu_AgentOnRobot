#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
çŸ¥è¯†åº“æ•°æ®è¿ç§»è„šæœ¬
ä»SimpleKnowledgeBaseè¿ç§»åˆ°LangChainçŸ¥è¯†åº“

åŠŸèƒ½:
- è‡ªåŠ¨æ£€æµ‹ç°æœ‰ç®€åŒ–ç‰ˆçŸ¥è¯†åº“
- è¿ç§»æ–‡æ¡£å’Œå…ƒæ•°æ®åˆ°LangChainç³»ç»Ÿ
- ä¿æŒåˆ†ç±»ä¿¡æ¯å’Œæ–‡ä»¶ç»“æ„
- ç”Ÿæˆè¿ç§»æŠ¥å‘Š

ä½œè€…: Dragon Robot AI System
åˆ›å»ºæ—¶é—´: 2024
"""

import os
import json
import logging
from pathlib import Path
from typing import Dict, List, Any, Tuple
import shutil
from datetime import datetime

# å¯¼å…¥çŸ¥è¯†åº“ç³»ç»Ÿ
from simple_knowledge_base import SimpleKnowledgeBase
from langchain_knowledge_base import LangChainKnowledgeBase

logger = logging.getLogger(__name__)

class KnowledgeBaseMigrator:
    """çŸ¥è¯†åº“è¿ç§»å·¥å…·"""
    
    def __init__(self, 
                 simple_kb_dir: str = "knowledge_base",
                 langchain_kb_dir: str = "langchain_knowledge_base"):
        """
        åˆå§‹åŒ–è¿ç§»å·¥å…·
        
        Args:
            simple_kb_dir: ç®€åŒ–ç‰ˆçŸ¥è¯†åº“ç›®å½•
            langchain_kb_dir: LangChainçŸ¥è¯†åº“ç›®å½•
        """
        self.simple_kb_dir = Path(simple_kb_dir)
        self.langchain_kb_dir = Path(langchain_kb_dir)
        
        # è¿ç§»æ—¥å¿—
        self.migration_log = {
            "migration_date": datetime.now().isoformat(),
            "source_dir": str(self.simple_kb_dir),
            "target_dir": str(self.langchain_kb_dir),
            "migrated_documents": [],
            "failed_documents": [],
            "statistics": {}
        }
        
        logger.info(f"è¿ç§»å·¥å…·åˆå§‹åŒ–: {self.simple_kb_dir} -> {self.langchain_kb_dir}")
    
    def check_source_kb(self) -> Tuple[bool, Dict[str, Any]]:
        """
        æ£€æŸ¥æºçŸ¥è¯†åº“çŠ¶æ€
        
        Returns:
            Tuple[bool, Dict]: (æ˜¯å¦å­˜åœ¨, ç»Ÿè®¡ä¿¡æ¯)
        """
        try:
            if not self.simple_kb_dir.exists():
                logger.warning(f"æºçŸ¥è¯†åº“ç›®å½•ä¸å­˜åœ¨: {self.simple_kb_dir}")
                return False, {}
            
            # åˆå§‹åŒ–ç®€åŒ–ç‰ˆçŸ¥è¯†åº“
            simple_kb = SimpleKnowledgeBase(str(self.simple_kb_dir))
            
            # è·å–ç»Ÿè®¡ä¿¡æ¯
            stats = {
                "documents_dir": str(self.simple_kb_dir / "documents"),
                "document_count": 0,
                "total_size": 0,
                "file_types": {},
                "categories": {}
            }
            
            documents_dir = self.simple_kb_dir / "documents"
            if documents_dir.exists():
                for file_path in documents_dir.rglob("*"):
                    if file_path.is_file():
                        stats["document_count"] += 1
                        stats["total_size"] += file_path.stat().st_size
                        
                        # ç»Ÿè®¡æ–‡ä»¶ç±»å‹
                        file_ext = file_path.suffix.lower()
                        stats["file_types"][file_ext] = stats["file_types"].get(file_ext, 0) + 1
            
            # æ£€æŸ¥å…ƒæ•°æ®æ–‡ä»¶
            metadata_file = self.simple_kb_dir / "metadata.json"
            if metadata_file.exists():
                try:
                    with open(metadata_file, 'r', encoding='utf-8') as f:
                        metadata = json.load(f)
                    
                    # ç»Ÿè®¡åˆ†ç±»ä¿¡æ¯
                    for doc_info in metadata.get("documents", {}).values():
                        category = doc_info.get("category", "unknown")
                        stats["categories"][category] = stats["categories"].get(category, 0) + 1
                        
                except Exception as e:
                    logger.warning(f"è¯»å–å…ƒæ•°æ®å¤±è´¥: {e}")
            
            logger.info(f"æºçŸ¥è¯†åº“æ£€æŸ¥å®Œæˆ: {stats}")
            return True, stats
            
        except Exception as e:
            logger.error(f"æ£€æŸ¥æºçŸ¥è¯†åº“å¤±è´¥: {e}")
            return False, {}
    
    def migrate_documents(self) -> bool:
        """
        è¿ç§»æ–‡æ¡£åˆ°LangChainçŸ¥è¯†åº“
        
        Returns:
            bool: è¿ç§»æ˜¯å¦æˆåŠŸ
        """
        try:
            # æ£€æŸ¥æºçŸ¥è¯†åº“
            exists, source_stats = self.check_source_kb()
            if not exists:
                logger.error("æºçŸ¥è¯†åº“ä¸å­˜åœ¨æˆ–æ— æ³•è®¿é—®")
                return False
            
            # åˆ›å»ºLangChainçŸ¥è¯†åº“
            logger.info("åˆå§‹åŒ–LangChainçŸ¥è¯†åº“...")
            langchain_kb = LangChainKnowledgeBase(str(self.langchain_kb_dir))
            
            # è·å–æºæ–‡æ¡£åˆ—è¡¨
            documents_dir = self.simple_kb_dir / "documents"
            if not documents_dir.exists():
                logger.warning("æºçŸ¥è¯†åº“æ²¡æœ‰documentsç›®å½•")
                return True  # ç©ºè¿ç§»ä¹Ÿç®—æˆåŠŸ
            
            # åŠ è½½æºå…ƒæ•°æ®
            source_metadata = self._load_source_metadata()
            
            # è¿ç§»æ¯ä¸ªæ–‡æ¡£
            success_count = 0
            total_count = 0
            
            for file_path in documents_dir.rglob("*"):
                if file_path.is_file():
                    total_count += 1
                    
                    # ç¡®å®šæ–‡æ¡£åˆ†ç±»
                    category = self._get_document_category(file_path, source_metadata)
                    
                    # è¿ç§»æ–‡æ¡£
                    if self._migrate_single_document(langchain_kb, file_path, category):
                        success_count += 1
                        self.migration_log["migrated_documents"].append({
                            "file": str(file_path),
                            "category": category,
                            "migrated_at": datetime.now().isoformat()
                        })
                    else:
                        self.migration_log["failed_documents"].append({
                            "file": str(file_path),
                            "category": category,
                            "error": "è¿ç§»å¤±è´¥"
                        })
            
            # æ›´æ–°è¿ç§»ç»Ÿè®¡
            self.migration_log["statistics"] = {
                "total_documents": total_count,
                "successful_migrations": success_count,
                "failed_migrations": total_count - success_count,
                "source_stats": source_stats,
                "target_stats": langchain_kb.get_stats()
            }
            
            # ä¿å­˜è¿ç§»æ—¥å¿—
            self._save_migration_log()
            
            logger.info(f"è¿ç§»å®Œæˆ: {success_count}/{total_count} ä¸ªæ–‡æ¡£æˆåŠŸè¿ç§»")
            return success_count > 0
            
        except Exception as e:
            logger.error(f"æ–‡æ¡£è¿ç§»å¤±è´¥: {e}")
            return False
    
    def _load_source_metadata(self) -> Dict[str, Any]:
        """åŠ è½½æºçŸ¥è¯†åº“å…ƒæ•°æ®"""
        metadata_file = self.simple_kb_dir / "metadata.json"
        if metadata_file.exists():
            try:
                with open(metadata_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except Exception as e:
                logger.warning(f"åŠ è½½æºå…ƒæ•°æ®å¤±è´¥: {e}")
        return {"documents": {}}
    
    def _get_document_category(self, file_path: Path, source_metadata: Dict[str, Any]) -> str:
        """è·å–æ–‡æ¡£åˆ†ç±»"""
        # ä»æºå…ƒæ•°æ®ä¸­æŸ¥æ‰¾åˆ†ç±»
        for doc_path, doc_info in source_metadata.get("documents", {}).items():
            if Path(doc_path).name == file_path.name:
                return doc_info.get("category", "general")
        
        # æ ¹æ®æ–‡ä»¶åæˆ–è·¯å¾„æ¨æ–­åˆ†ç±»
        file_name = file_path.name.lower()
        if "robot" in file_name or "æœºå™¨äºº" in file_name:
            return "robot"
        elif "voice" in file_name or "è¯­éŸ³" in file_name:
            return "voice"
        elif "manual" in file_name or "è¯´æ˜" in file_name:
            return "manual"
        else:
            return "general"
    
    def _migrate_single_document(self, langchain_kb: LangChainKnowledgeBase, 
                                file_path: Path, category: str) -> bool:
        """
        è¿ç§»å•ä¸ªæ–‡æ¡£
        
        Args:
            langchain_kb: LangChainçŸ¥è¯†åº“å®ä¾‹
            file_path: æ–‡æ¡£è·¯å¾„
            category: æ–‡æ¡£åˆ†ç±»
        
        Returns:
            bool: æ˜¯å¦æˆåŠŸ
        """
        try:
            logger.info(f"è¿ç§»æ–‡æ¡£: {file_path.name}")
            
            # å¤åˆ¶æ–‡æ¡£åˆ°æ–°çš„çŸ¥è¯†åº“ç›®å½•
            target_doc_path = langchain_kb.documents_dir / file_path.name
            shutil.copy2(file_path, target_doc_path)
            
            # æ·»åŠ åˆ°LangChainçŸ¥è¯†åº“
            success = langchain_kb.add_document(str(target_doc_path), category)
            
            if not success:
                # å¦‚æœæ·»åŠ å¤±è´¥ï¼Œåˆ é™¤å¤åˆ¶çš„æ–‡ä»¶
                if target_doc_path.exists():
                    target_doc_path.unlink()
                logger.error(f"æ–‡æ¡£æ·»åŠ åˆ°çŸ¥è¯†åº“å¤±è´¥: {file_path.name}")
                return False
            
            logger.info(f"æ–‡æ¡£è¿ç§»æˆåŠŸ: {file_path.name}")
            return True
            
        except Exception as e:
            logger.error(f"è¿ç§»å•ä¸ªæ–‡æ¡£å¤±è´¥ {file_path.name}: {e}")
            return False
    
    def _save_migration_log(self):
        """ä¿å­˜è¿ç§»æ—¥å¿—"""
        try:
            log_file = self.langchain_kb_dir / "migration_log.json"
            with open(log_file, 'w', encoding='utf-8') as f:
                json.dump(self.migration_log, f, ensure_ascii=False, indent=2)
            logger.info(f"è¿ç§»æ—¥å¿—å·²ä¿å­˜: {log_file}")
        except Exception as e:
            logger.error(f"ä¿å­˜è¿ç§»æ—¥å¿—å¤±è´¥: {e}")
    
    def create_backup(self) -> bool:
        """
        åˆ›å»ºæºçŸ¥è¯†åº“å¤‡ä»½
        
        Returns:
            bool: å¤‡ä»½æ˜¯å¦æˆåŠŸ
        """
        try:
            if not self.simple_kb_dir.exists():
                logger.warning("æºçŸ¥è¯†åº“ä¸å­˜åœ¨ï¼Œæ— éœ€å¤‡ä»½")
                return True
            
            backup_dir = self.simple_kb_dir.parent / f"{self.simple_kb_dir.name}_backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
            
            logger.info(f"åˆ›å»ºå¤‡ä»½: {self.simple_kb_dir} -> {backup_dir}")
            shutil.copytree(self.simple_kb_dir, backup_dir)
            
            logger.info(f"å¤‡ä»½åˆ›å»ºæˆåŠŸ: {backup_dir}")
            return True
            
        except Exception as e:
            logger.error(f"åˆ›å»ºå¤‡ä»½å¤±è´¥: {e}")
            return False
    
    def generate_migration_report(self) -> str:
        """
        ç”Ÿæˆè¿ç§»æŠ¥å‘Š
        
        Returns:
            str: æŠ¥å‘Šæ–‡æœ¬
        """
        report = f"""
=== Dragon Robot çŸ¥è¯†åº“è¿ç§»æŠ¥å‘Š ===

è¿ç§»æ—¶é—´: {self.migration_log['migration_date']}
æºç›®å½•: {self.migration_log['source_dir']}
ç›®æ ‡ç›®å½•: {self.migration_log['target_dir']}

=== è¿ç§»ç»Ÿè®¡ ===
æ€»æ–‡æ¡£æ•°: {self.migration_log['statistics'].get('total_documents', 0)}
æˆåŠŸè¿ç§»: {self.migration_log['statistics'].get('successful_migrations', 0)}
å¤±è´¥æ•°é‡: {self.migration_log['statistics'].get('failed_migrations', 0)}

=== æˆåŠŸè¿ç§»çš„æ–‡æ¡£ ===
"""
        for doc in self.migration_log['migrated_documents']:
            report += f"- {Path(doc['file']).name} (åˆ†ç±»: {doc['category']})\n"
        
        if self.migration_log['failed_documents']:
            report += "\n=== è¿ç§»å¤±è´¥çš„æ–‡æ¡£ ===\n"
            for doc in self.migration_log['failed_documents']:
                report += f"- {Path(doc['file']).name} (é”™è¯¯: {doc['error']})\n"
        
        # æ·»åŠ ç»Ÿè®¡å¯¹æ¯”
        source_stats = self.migration_log['statistics'].get('source_stats', {})
        target_stats = self.migration_log['statistics'].get('target_stats', {})
        
        report += f"""
=== çŸ¥è¯†åº“å¯¹æ¯” ===
æºçŸ¥è¯†åº“æ–‡æ¡£æ•°: {source_stats.get('document_count', 0)}
ç›®æ ‡çŸ¥è¯†åº“æ–‡æ¡£æ•°: {target_stats.get('total_documents', 0)}
ç›®æ ‡çŸ¥è¯†åº“åˆ†å—æ•°: {target_stats.get('total_chunks', 0)}

=== è¿ç§»å®Œæˆ ===
LangChainçŸ¥è¯†åº“å·²å°±ç»ªï¼Œæ”¯æŒè¯­ä¹‰æœç´¢å’Œå‘é‡æ£€ç´¢ã€‚
"""
        return report


def main():
    """ä¸»å‡½æ•° - æ‰§è¡Œè¿ç§»"""
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    print("=== Dragon Robot çŸ¥è¯†åº“è¿ç§»å·¥å…· ===")
    print("å°†ç®€åŒ–ç‰ˆçŸ¥è¯†åº“è¿ç§»åˆ°LangChainç³»ç»Ÿ")
    
    # åˆ›å»ºè¿ç§»å™¨
    migrator = KnowledgeBaseMigrator()
    
    # æ£€æŸ¥æºçŸ¥è¯†åº“
    print("\n1. æ£€æŸ¥æºçŸ¥è¯†åº“...")
    exists, stats = migrator.check_source_kb()
    
    if not exists:
        print("âŒ æºçŸ¥è¯†åº“ä¸å­˜åœ¨æˆ–ä¸ºç©ºï¼Œæ— éœ€è¿ç§»")
        return
    
    print(f"âœ… æºçŸ¥è¯†åº“æ£€æŸ¥å®Œæˆ:")
    print(f"   - æ–‡æ¡£æ•°é‡: {stats.get('document_count', 0)}")
    print(f"   - æ–‡ä»¶ç±»å‹: {list(stats.get('file_types', {}).keys())}")
    print(f"   - åˆ†ç±»æ•°é‡: {len(stats.get('categories', {}))}")
    
    # è¯¢é—®æ˜¯å¦åˆ›å»ºå¤‡ä»½
    backup_choice = input("\n2. æ˜¯å¦åˆ›å»ºæºçŸ¥è¯†åº“å¤‡ä»½? (y/N): ").lower().strip()
    if backup_choice == 'y':
        print("åˆ›å»ºå¤‡ä»½ä¸­...")
        if migrator.create_backup():
            print("âœ… å¤‡ä»½åˆ›å»ºæˆåŠŸ")
        else:
            print("âŒ å¤‡ä»½åˆ›å»ºå¤±è´¥")
            return
    
    # æ‰§è¡Œè¿ç§»
    print("\n3. å¼€å§‹è¿ç§»æ–‡æ¡£...")
    if migrator.migrate_documents():
        print("âœ… æ–‡æ¡£è¿ç§»å®Œæˆ")
        
        # ç”ŸæˆæŠ¥å‘Š
        print("\n4. ç”Ÿæˆè¿ç§»æŠ¥å‘Š...")
        report = migrator.generate_migration_report()
        print(report)
        
        # ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶
        report_file = Path("migration_report.txt")
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(report)
        print(f"ğŸ“ å®Œæ•´æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")
        
    else:
        print("âŒ æ–‡æ¡£è¿ç§»å¤±è´¥")
        return
    
    print("\n=== è¿ç§»å®Œæˆ ===")
    print("LangChainçŸ¥è¯†åº“å·²å°±ç»ªï¼Œç°åœ¨å¯ä»¥äº«å—è¯­ä¹‰æœç´¢åŠŸèƒ½ï¼")


if __name__ == "__main__":
    main()